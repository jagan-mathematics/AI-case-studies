{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class ModelConfigs:\n",
        "  d_model = 512\n",
        "  model_max_sequence = 68\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding comprises sinusoidal waves which works based on the wavelength\n",
        "    and frequency of the rotation across dimension.\n",
        "\n",
        "    P_E(pos,2i) = sin(pos/10000^(2i/dmodel))\n",
        "    P_E(pos,2i+1) = cos(pos/10000^(2i/dmodel))\n",
        "\n",
        "    L => Seq_len\n",
        "    D => dim\n",
        "    B => Batch_size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfigs):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        depth = config.d_model / 2\n",
        "        pe = torch.zeros(config.model_max_sequence, config.d_model)  # (L x D)\n",
        "        position = torch.arange(0, config.model_max_sequence, dtype=torch.float).unsqueeze(1)  # (L x 1)\n",
        "        depths = torch.arange(0, depth).unsqueeze(0) / depth  # (1 x D // 2)\n",
        "        angle_rate = 1 / (10000 ** depths)  # angle rate is an monotonically increasing function (1 x D // 2)\n",
        "        angle_rads = position * angle_rate  # (L x D // 2)\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(angle_rads)  # replace every position with sin wave\n",
        "        pe[:, 1::2] = torch.cos(angle_rads)  # replace every position with cos wave\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))  # saved as buffer with dim => (1 x L x D)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"model forward pass\"\"\"\n",
        "        return x + self.pe[:, :x.size(1)]\n"
      ],
      "metadata": {
        "id": "8R-CDLymQzD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positional_encoder = PositionalEncoding(ModelConfigs)"
      ],
      "metadata": {
        "id": "aUQN5zXtJtsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "\n",
        "plt.subplot(224)\n",
        "plt.title('d = 512')\n",
        "a = positional_encoder.pe.squeeze(0)\n",
        "sns.heatmap(a @ a.T)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l4O2fQ-uJtu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "plt.title('d = 512')\n",
        "d = 512\n",
        "pos_encoding = a.reshape(ModelConfigs.model_max_sequence, d//2, 2)\n",
        "pos_encoding = pos_encoding.permute(2, 1, 0)\n",
        "pos_encoding = pos_encoding.reshape(d, ModelConfigs.model_max_sequence)\n",
        "\n",
        "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
        "plt.ylabel('Depth')\n",
        "plt.xlabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MqQ-noiELbDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kk6IeFbP0ei"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
